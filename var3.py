# -*- coding: utf-8 -*-
"""var3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xrOaan-qiRMf8fCgdIIk-7JZenJfy2GB

4. Variant 3: Add a few dropout layers in the model. Would the performance improve? Try 2
different ways to add the dropout layers. Describe the ones you tried and their performance.
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers.convolutional import Conv2D, Conv3D
from keras.layers.convolutional import MaxPooling2D, MaxPooling3D 
from keras.losses import CategoricalCrossentropy
from keras.utils import to_categorical
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dropout
from keras.layers.core import Dense
from keras.optimizers import SGD
from sklearn.model_selection import train_test_split
from matplotlib import pyplot
import matplotlib.pyplot as plt
import numpy as np
# %matplotlib inline
import sys
import time

# using cifar-10 dataset from TensorFlow
(x_train, y_train), (x_test_base, y_test_base) = cifar10.load_data()
x_test, x_val, y_test, y_val = train_test_split(x_test_base, y_test_base, test_size=0.5)

print("x_train shape", x_train.shape)
print("x_test shape", x_test.shape)
print("x_val shape", x_val.shape)
print("y_train shape", y_train.shape)
print("y_test shape", y_test.shape)
print("y_val shape", y_val.shape)

#Prepare Dataset:
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
y_val = to_categorical(y_val)

x_train = x_train.astype("float") / 255.0 
x_test = x_test.astype("float") / 255.0 
x_val = x_val.astype("float")/255.0

"""1st way to implement dropout"""

class MiniVGG:
 
  def build(height, width, depth, classes):
    model = Sequential()
    inputShape = (height, width, depth)
   
    #The layer configuration:
    
    # first Conv3-64 -> Conv3-64 -> Maxpool(2x2) 
    model.add(Conv2D(64, (3, 3),  activation='relu', padding="same", input_shape=inputShape))
    model.add(Conv2D(64, (3, 3), activation='relu', padding="same"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.3))
  

    # second Conv3-128 -> Conv3-128 -> Maxpool(2x2) 
    model.add(Conv2D(128, (3, 3), activation='relu', padding="same"))
    model.add(Conv2D(128, (3, 3), activation='relu', padding="same"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.3))
    

    # third Conv3-256 -> Conv3-256 -> Maxpool(2x2)  
    model.add(Conv2D(256, (3, 3), activation='relu', padding="same"))
    model.add(Conv2D(256, (3, 3), activation='relu', padding="same"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.3))

    # Flatten -> FC-512 -> Output
    model.add(Flatten())
    model.add(Dense(512,  activation='relu'))
    
      # softmax classifier
    model.add(Dense(10, activation='softmax' ))
 
    return model

model = MiniVGG.build(height = 32,width = 32, depth = 3, classes=10)
model.summary()

model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=SGD(learning_rate= 0.001), metrics=['accuracy'])

start_time = round(time.time() * 1000)

pred_history = model.fit(x_train, y_train, validation_data=(x_val, y_val),batch_size=64, epochs=20, verbose=1)

total_train_time = round(time.time() * 1000) - start_time
print('Total Train Time: %d' % (total_train_time))

test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print('Test Accuracy: %.3f' % (test_accuracy[1] * 100.0))

val_accuracy = model.evaluate(x_val, y_val, verbose=0)
print('Val Accuracy: %.3f' % (val_accuracy[1] * 100.0))

plt.figure(figsize=(4, 6))
plt.plot(np.arange(0, 20), pred_history.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, 20), pred_history.history["val_accuracy"], label="val_acc")
plt.title("Training Accuracy vs Validation Accuracy")
plt.xlabel("Number of Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

plt.figure(figsize=(4, 6))
plt.plot(np.arange(0, 20), pred_history.history["loss"], label="train_loss")
plt.plot(np.arange(0, 20), pred_history.history["val_loss"], label="val_loss")
plt.title("Training Loss vs Validation Loss")
plt.xlabel("Number of Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

"""2nd way to implement dropouts"""

class MiniVGG2:
 
  def build2(height, width, depth, classes):
    model2 = Sequential()
    inputShape = (height, width, depth)
   
    #The layer configuration:
    
    # first Conv3-64 -> Conv3-64 -> Maxpool(2x2) 
    model2.add(Conv2D(64, (3, 3),  activation='relu', padding="same", input_shape=inputShape))
    model2.add(Conv2D(64, (3, 3), activation='relu', padding="same"))
    model2.add(MaxPooling2D(pool_size=(2, 2)))
    model2.add(Dropout(0.2))
  

    # second Conv3-128 -> Conv3-128 -> Maxpool(2x2) 
    model2.add(Conv2D(128, (3, 3), activation='relu', padding="same"))
    model2.add(Conv2D(128, (3, 3), activation='relu', padding="same"))
    model2.add(MaxPooling2D(pool_size=(2, 2)))
    model2.add(Dropout(0.3))
    

    # third Conv3-256 -> Conv3-256 -> Maxpool(2x2)  
    model2.add(Conv2D(256, (3, 3), activation='relu', padding="same"))
    model2.add(Conv2D(256, (3, 3), activation='relu', padding="same"))
    model2.add(MaxPooling2D(pool_size=(2, 2)))
    model2.add(Dropout(0.4))

    # Flatten -> FC-512 -> Output
    model2.add(Flatten())
    model2.add(Dense(512,  activation='relu'))
    
      # softmax classifier
    model2.add(Dense(10, activation='softmax' ))
 
    return model2

model2 = MiniVGG2.build2(height = 32,width = 32, depth = 3, classes=10)
model2.summary()

model2.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer=SGD(learning_rate= 0.001), metrics=['accuracy'])

start_time2 = round(time.time() * 1000)

pred_history2 = model2.fit(x_train, y_train, validation_data=(x_val, y_val),batch_size=64, epochs=20, verbose=1)

total_train_time2 = round(time.time() * 1000) - start_time2
print('Total Train Time2: %d' % (total_train_time2))

Test_accuracy_model2 = model2.evaluate(x_test, y_test, verbose=0)
print('Test_accuracy_model2: %.3f' % (Test_accuracy_model2[1] * 100.0))

val_accuracy_model2 = model2.evaluate(x_val, y_val, verbose=0)
print('Val Accuracy_model2: %.3f' % (val_accuracy_model2[1] * 100.0))

plt.figure(figsize=(4, 6))
plt.plot(np.arange(0, 20), pred_history2.history["accuracy"], label="train_acc")
plt.plot(np.arange(0, 20), pred_history2.history["val_accuracy"], label="val_acc")
plt.title("Training Accuracy vs Validation Accuracy")
plt.xlabel("Number of Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

plt.figure(figsize=(4, 6))
plt.plot(np.arange(0, 20), pred_history2.history["loss"], label="train_loss")
plt.plot(np.arange(0, 20), pred_history2.history["val_loss"], label="val_loss")
plt.title("Training Loss vs Validation Loss")
plt.xlabel("Number of Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()